version: '3.8'

services:
  # Redis f√ºr Message Queue und Stream-Koordination
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  # Telephony Bridge - WebSocket-Server
  telephony-bridge:
    build:
      context: ..
      dockerfile: infra/Dockerfile.telephony-bridge
    ports:
      - "8080:8080"
    environment:
      - REDIS_URL=redis://redis:6379/0
      - WEBSOCKET_PORT=8080
      - LOG_LEVEL=INFO
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ../apps:/app/apps
      - ../data/runtime:/app/data/runtime
    restart: unless-stopped

  # STT Stream Worker
  stt-worker:
    build:
      context: ..
      dockerfile: infra/Dockerfile.stt-worker
    environment:
      - REDIS_URL=redis://redis:6379/0
      - STT_MODEL_PATH=/app/models/stt
      - AUDIO_SAMPLE_RATE=16000
      - AUDIO_CHUNK_SIZE=1024
      - LOG_LEVEL=INFO
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ../apps:/app/apps
      - ../data/runtime:/app/data/runtime
      - stt_models:/app/models/stt
    restart: unless-stopped

  # LLM Stream Worker
  llm-worker:
    build:
      context: ..
      dockerfile: infra/Dockerfile.llm-worker
    environment:
      - REDIS_URL=redis://redis:6379/0
      - LLM_API_KEY=${LLM_API_KEY}
      - LLM_MODEL=gpt-3.5-turbo
      - LOG_LEVEL=INFO
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ../apps:/app/apps
      - ../data/runtime:/app/data/runtime
    restart: unless-stopped

  # TTS Stream Worker
  tts-worker:
    build:
      context: ..
      dockerfile: infra/Dockerfile.tts-worker
    environment:
      - REDIS_URL=redis://redis:6379/0
      - TTS_MODEL_PATH=/app/models/tts
      - AUDIO_SAMPLE_RATE=16000
      - LOG_LEVEL=INFO
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ../apps:/app/apps
      - ../data/runtime:/app/data/runtime
      - tts_models:/app/models/tts
    restart: unless-stopped

  # Dispatcher FSM
  dispatcher:
    build:
      context: ..
      dockerfile: infra/Dockerfile.dispatcher
    environment:
      - REDIS_URL=redis://redis:6379/0
      - MAX_CONCURRENT_CALLS=10
      - LOG_LEVEL=INFO
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ../apps:/app/apps
      - ../data/runtime:/app/data/runtime
    restart: unless-stopped

  # Monitor & Metrics
  monitor:
    build:
      context: ..
      dockerfile: infra/Dockerfile.monitor
    ports:
      - "9090:9090"
    environment:
      - REDIS_URL=redis://redis:6379/0
      - PROM_PORT=9090
      - LOG_LEVEL=INFO
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ../apps:/app/apps
      - ../data/runtime:/app/data/runtime
    restart: unless-stopped

  # Nginx Load Balancer
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ../web/dashboard/dist:/usr/share/nginx/html:ro
    depends_on:
      - telephony-bridge
      - monitor
    restart: unless-stopped

volumes:
  redis_data:
  stt_models:
  tts_models:

networks:
  default:
    name: tom_realtime_network
