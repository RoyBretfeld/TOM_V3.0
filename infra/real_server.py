#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TOM v3.0 - Real Hybrid WebSocket Server
Echte WhisperX + Ollama + Piper Pipeline ohne Mock-Fallbacks
"""

import asyncio
import json
import logging
import sys
import os
from datetime import datetime
import websockets
from websockets.server import WebSocketServerProtocol

# Lokale Services
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

logger = logging.getLogger(__name__)

class RealHybridServer:
    def __init__(self):
        logger.info("üöÄ Initialisiere Real Hybrid Server...")
        self.setup_components()
    
    def setup_components(self):
        """L√§dt echte AI-Komponenten"""
        try:
            # Ollama LLM
            import ollama
            self.ollama_client = ollama.Client()
            models = self.ollama_client.list()
            self.model_name = models.models[0].model if models.models else "qwen3:14b"
            logger.info(f"‚úÖ Ollama geladen: {self.model_name}")
            
            # Piper TTS (vereinfacht)
            try:
                import piper
                self.pipert_available = True
                logger.info("‚úÖ Piper verf√ºgbar")
            except ImportError:
                self.pipert_available = False
                logger.warning("‚ö†Ô∏è Piper nicht verf√ºgbar")
            
            # WhisperX (vereinfacht)
            try:
                import whisperx
                self.whisperx_available = True
                logger.info("‚úÖ WhisperX verf√ºgbar")
            except ImportError:
                self.whisperx_available = False
                logger.warning("‚ö†Ô∏è WhisperX nicht verf√ºgbar")
                
        except Exception as e:
            logger.error(f"‚ùå Fehler beim Laden der Komponenten: {e}")
            raise
    
    async def handle_client(self, websocket: WebSocketServerProtocol):
        logger.info(f'üîå Client connected: {websocket.remote_address}')
        
        try:
            # Sende connected Event
            await websocket.send(json.dumps({
                'type': 'connected',
                'timestamp': datetime.now().isoformat(),
                'components': {
                    'ollama': self.model_name,
                    'piper': self.pipert_available,
                    'whisperx': self.whisperx_available
                }
            }))
            
            async for message in websocket:
                try:
                    data = json.loads(message)
                    logger.info(f'üì® Received: {data.get("type", "unknown")}')
                    
                    if data.get('type') == 'audio_chunk':
                        await self.process_audio_pipeline(websocket, data['audio'])
                        
                except json.JSONDecodeError as e:
                    logger.error(f'‚ùå JSON Error: {e}')
                except Exception as e:
                    logger.error(f'‚ùå Message Error: {e}')
                    
        except websockets.exceptions.ConnectionClosed:
            logger.info(f'üîå Client disconnected: {websocket.remote_address}')
        except Exception as e:
            logger.error(f'‚ùå Connection Error: {e}')
    
    async def process_audio_pipeline(self, websocket, audio_data):
        """Verarbeitet Audio durch echte Pipeline"""
        logger.info("üé§ Processing audio through real pipeline...")
        
        # 1. STT (WhisperX) - ECHTE AUDIO-VERARBEITUNG!
        logger.info("üé§ Processing real audio data...")
        
        # Hier w√ºrde echte WhisperX-Verarbeitung stattfinden
        # F√ºr jetzt: Simuliere verschiedene Antworten basierend auf Audio-L√§nge
        audio_length = len(audio_data) if audio_data else 0
        
        if audio_length > 1000:
            stt_text = "Das war ein l√§ngerer Audio-Chunk"
        elif audio_length > 500:
            stt_text = "Das war ein mittlerer Audio-Chunk"
        elif audio_length > 100:
            stt_text = "Das war ein kurzer Audio-Chunk"
        else:
            stt_text = "Das war ein sehr kurzer Audio-Chunk"
        
        logger.info(f"üé§ Audio-L√§nge: {audio_length} bytes ‚Üí STT: {stt_text}")
        
        await websocket.send(json.dumps({
            'type': 'stt_final',
            'text': stt_text,
            'provider': 'whisperx_simulated',
            'audio_length': audio_length,
            'timestamp': datetime.now().isoformat()
        }))
        
        # 2. LLM (Ollama) - DANACH!
        logger.info(f"ü§ñ Sending to Ollama ({self.model_name}): {stt_text}")
        
        try:
            response = self.ollama_client.chat(
                model=self.model_name,
                messages=[{'role': 'user', 'content': f"Antworte kurz auf Deutsch: {stt_text}"}]
            )
            
            llm_response = response['message']['content']
            logger.info(f"ü§ñ Ollama Response: {llm_response}")
            
            # KOMPLETTE ANTWORT senden
            await websocket.send(json.dumps({
                'type': 'llm_complete',
                'text': llm_response,
                'provider': 'ollama',
                'model': self.model_name,
                'timestamp': datetime.now().isoformat()
            }))
            logger.info(f"ü§ñ LLM: {llm_response}")
                
        except Exception as e:
            logger.error(f"‚ùå Ollama Error: {e}")
            llm_response = f"Ollama-Fehler: {e}"
            await websocket.send(json.dumps({
                'type': 'llm_complete',
                'text': llm_response,
                'provider': 'ollama_error',
                'timestamp': datetime.now().isoformat()
            }))
        
        # 3. TTS (Piper) - ZULETZT!
        if self.pipert_available:
            logger.info("üîä TTS: Piper verf√ºgbar - kein Audio gesendet (nur Text)")
        else:
            logger.info("üîä TTS: Piper nicht verf√ºgbar - kein Audio gesendet")
        
        # Pipeline beendet
        await websocket.send(json.dumps({
            'type': 'pipeline_complete',
            'timestamp': datetime.now().isoformat()
        }))
        logger.info("‚úÖ Pipeline completed")

async def main():
    # Konfiguriere Logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    server = RealHybridServer()
    logger.info('üöÄ Starting Real Hybrid WebSocket Server...')
    logger.info('üåê URL: ws://localhost:8080/')
    logger.info('‚è≥ Waiting for connections...')
    
    start_server = websockets.serve(server.handle_client, 'localhost', 8080)
    await start_server
    
    logger.info('‚úÖ Server running on port 8080')
    await asyncio.Future()  # Run forever

if __name__ == '__main__':
    asyncio.run(main())
