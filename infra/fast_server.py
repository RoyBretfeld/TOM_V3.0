#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TOM v3.0 - Fast Real Hybrid WebSocket Server
ECHTE WhisperX + Ollama + Piper Pipeline - SCHNELL!
"""

import asyncio
import json
import logging
import sys
import os
import time
from datetime import datetime
import websockets
from websockets.server import WebSocketServerProtocol

# Lokale Services
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

logger = logging.getLogger(__name__)

class FastHybridServer:
    def __init__(self):
        logger.info("üöÄ Initialisiere Fast Hybrid Server...")
        self.setup_components()
        self.audio_buffer = []  # Sammelt Audio-Chunks
        self.last_process_time = 0
        self.session_id = None  # F√ºr Audio-Dateien
        self.audio_file_path = None  # Pfad zur aktuellen Audio-Datei
    
    def setup_components(self):
        """L√§dt echte AI-Komponenten"""
        try:
            # Ollama LLM
            import ollama
            self.ollama_client = ollama.Client()
            models = self.ollama_client.list()
            self.model_name = models.models[0].model if models.models else "qwen3:14b"
            logger.info(f"‚úÖ Ollama geladen: {self.model_name}")
            
            # Piper TTS (vereinfacht)
            try:
                import piper
                self.pipert_available = True
                logger.info("‚úÖ Piper verf√ºgbar")
            except ImportError:
                self.pipert_available = False
                logger.warning("‚ö†Ô∏è Piper nicht verf√ºgbar")
            
            # WhisperX - ECHT LADEN!
            try:
                import whisperx
                import torch
                
                # Device bestimmen
                self.device = "cuda" if torch.cuda.is_available() else "cpu"
                self.compute_type = "float16" if self.device == "cuda" else "int8"
                
                logger.info(f"üé§ Lade WhisperX auf {self.device}...")
                
                # WhisperX-Modell laden
                self.whisperx_model = whisperx.load_model(
                    "large-v2", 
                    self.device, 
                    compute_type=self.compute_type,
                    language="de"  # Deutsch
                )
                
                # VAD-Modell f√ºr bessere Segmentierung (optional)
                try:
                    self.vad_model = whisperx.load_vad_model(self.device)
                    logger.info("‚úÖ VAD-Modell geladen")
                except AttributeError:
                    logger.warning("‚ö†Ô∏è VAD-Modell nicht verf√ºgbar - verwende ohne VAD")
                    self.vad_model = None
                
                self.whisperx_available = True
                logger.info("‚úÖ WhisperX ECHT geladen!")
                
            except Exception as e:
                logger.error(f"‚ùå WhisperX Fehler: {e}")
                self.whisperx_available = False
                self.whisperx_model = None
                self.vad_model = None
                
        except Exception as e:
            logger.error(f"‚ùå Fehler beim Laden der Komponenten: {e}")
            raise
    
    async def handle_client(self, websocket: WebSocketServerProtocol):
        logger.info(f'üîå Client connected: {websocket.remote_address}')
        
        # Neue Session starten
        self.session_id = f"session_{int(time.time())}"
        self.audio_buffer = []
        
        try:
            # Sende connected Event
            await websocket.send(json.dumps({
                'type': 'connected',
                'timestamp': datetime.now().isoformat(),
                'session_id': self.session_id,
                'components': {
                    'ollama': self.model_name,
                    'piper': self.pipert_available,
                    'whisperx': self.whisperx_available
                }
            }))
            
            async for message in websocket:
                try:
                    data = json.loads(message)
                    
                    if data.get('type') == 'audio_chunk':
                        await self.buffer_and_process_audio(websocket, data['audio'])
                    elif data.get('type') == 'audio_end':
                        await self.finalize_audio_processing(websocket)
                        
                except json.JSONDecodeError as e:
                    logger.error(f'‚ùå JSON Error: {e}')
                except Exception as e:
                    logger.error(f'‚ùå Message Error: {e}')
                    
        except websockets.exceptions.ConnectionClosed:
            logger.info(f'üîå Client disconnected: {websocket.remote_address}')
            self.cleanup_session()
        except Exception as e:
            logger.error(f'‚ùå Connection Error: {e}')
            self.cleanup_session()
    
    async def buffer_and_process_audio(self, websocket, audio_data):
        """Buffer Audio-Chunks und verarbeite sie"""
        current_time = time.time()
        
        # Rate Limiting: Max 1x pro Sekunde
        if current_time - self.last_process_time < 1.0:
            # Audio trotzdem buffern
            self.audio_buffer.extend(audio_data)
            logger.debug(f"üé§ Audio gebuffert: {len(audio_data)} bytes (Total: {len(self.audio_buffer)})")
            return
        
        self.last_process_time = current_time
        
        # Audio zu Buffer hinzuf√ºgen
        self.audio_buffer.extend(audio_data)
        logger.info(f"üé§ Audio gebuffert: {len(audio_data)} bytes (Total: {len(self.audio_buffer)})")
        
        # Wenn genug Audio vorhanden ist, verarbeite es
        if len(self.audio_buffer) > 16000:  # ~1 Sekunde bei 16kHz
            await self.process_buffered_audio(websocket)
    
    async def finalize_audio_processing(self, websocket):
        """Verarbeite restlichen Audio-Buffer"""
        if self.audio_buffer:
            logger.info(f"üé§ Finalisiere Audio-Verarbeitung: {len(self.audio_buffer)} bytes")
            await self.process_buffered_audio(websocket)
        else:
            logger.info("üé§ Kein Audio zu verarbeiten")
    
    async def process_buffered_audio(self, websocket):
        """Verarbeite gebuffertes Audio mit WhisperX"""
        if not self.audio_buffer:
            return
            
        logger.info(f"üé§ Verarbeite {len(self.audio_buffer)} Audio-Bytes mit WhisperX...")
        
        # Speichere Audio in tempor√§rer Datei
        audio_file_path = await self.save_audio_to_file()
        
        stt_text = "Keine Spracherkennung verf√ºgbar"
        
        if self.whisperx_available and self.whisperx_model and audio_file_path:
            try:
                # WhisperX-Transkription von Datei
                result = self.whisperx_model.transcribe(audio_file_path)
                
                if result and 'segments' in result and result['segments']:
                    # Alle Segmente zusammenfassen
                    texts = []
                    for segment in result['segments']:
                        text = segment.get('text', '').strip()
                        if text:
                            texts.append(text)
                    
                    stt_text = ' '.join(texts) if texts else "Audio erkannt, aber kein Text"
                    
                    logger.info(f"üé§ WhisperX erkannt: '{stt_text}'")
                else:
                    stt_text = "Audio erkannt, aber kein Text"
                    logger.warning("‚ö†Ô∏è WhisperX: Kein Text erkannt")
                    
            except Exception as e:
                logger.error(f"‚ùå WhisperX Fehler: {e}")
                stt_text = f"STT-Fehler: {e}"
        else:
            logger.warning("‚ö†Ô∏è WhisperX nicht verf√ºgbar - verwende Fallback")
            stt_text = f"Audio empfangen ({len(self.audio_buffer)} bytes) - WhisperX nicht verf√ºgbar"
        
        # Audio-Buffer leeren
        self.audio_buffer = []
        
        await websocket.send(json.dumps({
            'type': 'stt_final',
            'text': stt_text,
            'provider': 'whisperx_real' if self.whisperx_available else 'fallback',
            'audio_length': len(self.audio_buffer),
            'audio_file': audio_file_path,
            'timestamp': datetime.now().isoformat()
        }))
        
        # LLM-Verarbeitung
        await self.process_llm_response(websocket, stt_text)
    
    async def save_audio_to_file(self):
        """Speichere Audio-Buffer in tempor√§rer Datei"""
        if not self.audio_buffer:
            return None
            
        try:
            # Erstelle Audio-Verzeichnis
            audio_dir = os.path.join(os.path.dirname(__file__), '..', 'data', 'audio')
            os.makedirs(audio_dir, exist_ok=True)
            
            # Generiere Dateiname
            timestamp = int(time.time())
            filename = f"{self.session_id}_{timestamp}.wav"
            audio_file_path = os.path.join(audio_dir, filename)
            
            # Konvertiere Audio-Buffer zu WAV-Datei
            import wave
            import numpy as np
            
            # Audio-Buffer zu numpy-Array
            audio_array = np.array(self.audio_buffer, dtype=np.int16)
            
            # WAV-Datei schreiben
            with wave.open(audio_file_path, 'wb') as wav_file:
                wav_file.setnchannels(1)  # Mono
                wav_file.setsampwidth(2)  # 16-bit
                wav_file.setframerate(16000)  # 16kHz
                wav_file.writeframes(audio_array.tobytes())
            
            logger.info(f"üíæ Audio gespeichert: {audio_file_path}")
            return audio_file_path
            
        except Exception as e:
            logger.error(f"‚ùå Fehler beim Speichern von Audio: {e}")
            return None
    
    async def process_llm_response(self, websocket, stt_text):
        """Verarbeite LLM-Antwort"""
        logger.info(f"ü§ñ LLM: {stt_text}")
        
        try:
            response = self.ollama_client.chat(
                model=self.model_name,
                messages=[{'role': 'user', 'content': f"Antworte kurz auf Deutsch: {stt_text}"}]
            )
            
            llm_response = response['message']['content']
            logger.info(f"ü§ñ Response: {llm_response}")
            
            await websocket.send(json.dumps({
                'type': 'llm_complete',
                'text': llm_response,
                'provider': 'ollama',
                'model': self.model_name,
                'timestamp': datetime.now().isoformat()
            }))
                
        except Exception as e:
            logger.error(f"‚ùå Ollama Error: {e}")
            await websocket.send(json.dumps({
                'type': 'llm_complete',
                'text': f"Fehler: {e}",
                'provider': 'ollama_error',
                'timestamp': datetime.now().isoformat()
            }))
        
        # Pipeline beendet
        await websocket.send(json.dumps({
            'type': 'pipeline_complete',
            'timestamp': datetime.now().isoformat()
        }))
        
        logger.info("‚úÖ Pipeline completed")
    
    def cleanup_session(self):
        """R√§ume Session auf"""
        if self.audio_file_path and os.path.exists(self.audio_file_path):
            try:
                os.remove(self.audio_file_path)
                logger.info(f"üóëÔ∏è Audio-Datei gel√∂scht: {self.audio_file_path}")
            except Exception as e:
                logger.error(f"‚ùå Fehler beim L√∂schen der Audio-Datei: {e}")
        
        self.audio_buffer = []
        self.session_id = None
        self.audio_file_path = None
    

async def main():
    # Konfiguriere Logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    server = FastHybridServer()
    logger.info('üöÄ Starting Fast Hybrid WebSocket Server...')
    logger.info('üåê URL: ws://localhost:8081/')
    logger.info('‚ö° SCHNELLER MODUS - Rate Limited!')
    
    start_server = websockets.serve(server.handle_client, 'localhost', 8081)
    await start_server
    
    logger.info('‚úÖ Fast Server running on port 8081')
    await asyncio.Future()  # Run forever

if __name__ == '__main__':
    asyncio.run(main())
